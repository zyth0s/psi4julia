{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Manipulation: Psi4 and NumPy manipulation routines\n",
    "Contracting tensors together forms the core of the Psi4Julia project. First let us consider the popluar [Einstein Summation Notation](https://en.wikipedia.org/wiki/Einstein_notation) which allows for very succinct descriptions of a given tensor contraction.\n",
    "\n",
    "For example, let us consider a [inner (dot) product](https://en.wikipedia.org/wiki/Dot_product):\n",
    "$$c = \\sum_{ij} A_{ij} * B_{ij}$$\n",
    "\n",
    "With the Einstein convention, all indices that are repeated are considered summed over, and the explicit summation symbol is dropped:\n",
    "$$c = A_{ij} * B_{ij}$$\n",
    "\n",
    "This can be extended to [matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication):\n",
    "\\begin{align}\n",
    "\\rm{Conventional}\\;\\;\\;  C_{ik} &= \\sum_{j} A_{ij} * B_{jk} \\\\\n",
    "\\rm{Einstein}\\;\\;\\;  C &= A_{ij} * B_{jk} \\\\\n",
    "\\end{align}\n",
    "\n",
    "Where the $C$ matrix has *implied* indices of $C_{ik}$ as the only repeated index is $j$.\n",
    "\n",
    "However, there are many cases where this notation fails. Thus we often use the generalized Einstein convention. To demonstrate let us examine a [Hadamard product](https://en.wikipedia.org/wiki/Hadamard_product_(matrices)):\n",
    "$$C_{ij} = \\sum_{ij} A_{ij} * B_{ij}$$\n",
    "\n",
    "\n",
    "This operation is nearly identical to the dot product above, and is not able to be written in pure Einstein convention. The generalized convention allows for the use of indices on the left hand side of the equation:\n",
    "$$C_{ij} = A_{ij} * B_{ij}$$\n",
    "\n",
    "Usually it should be apparent within the context the exact meaning of a given expression.\n",
    "\n",
    "Finally we also make use of Matrix notation:\n",
    "\\begin{align}\n",
    "{\\rm Matrix}\\;\\;\\;  \\bf{D} &= \\bf{A B C} \\\\\n",
    "{\\rm Einstein}\\;\\;\\;  D_{il} &= A_{ij} B_{jk} C_{kl}\n",
    "\\end{align}\n",
    "\n",
    "Note that this notation is signified by the use of bold characters to denote matrices and consecutive matrices next to each other imply a chain of matrix multiplications! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n",
    "To perform most operations we turn to tensor packages (here we use [TensorOperations.jl](https://github.com/Jutho/TensorOperations.jl)). Those allow Einstein convention as an input. In addition to being much easier to read, manipulate, and change, it has (usually) optimal performance.\n",
    "First let us import our normal suite of modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall: pyimport\n",
    "psi4 = pyimport(\"psi4\")\n",
    "np   = pyimport(\"numpy\")\n",
    "using TensorOperations: @tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use conventional Julia loops or `@tensor` to perform the same task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools: @btime, @belapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `@btime`/`@belapsed` we average time over several executions to have more reliable timings than `@time`/`@elapsed` (single execution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**WARNING: We are using Julia's global variables, and those are known to be less efficient than local variables. It is better to wrap code inside function.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin let us consider the construction of the following tensor (which you may recognize):\n",
    "$$G_{pq} = 2.0 * I_{pqrs} D_{rs} - 1.0 * I_{prqs} D_{rs}$$ \n",
    "\n",
    "Keep size relatively small as these 4-index tensors grow very quickly in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for loop G build:\n",
      "  81.372 ms (2400038 allocations: 61.04 MiB)\n",
      "Time for @tensor G build:\n",
      "  264.983 μs (46 allocations: 5.75 KiB)\n",
      "Loop and einsum builds of the Fock matrix match?    true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dims = 20\n",
    "\n",
    "@assert dims <= 30 \"Size must be smaller than 30.\"\n",
    "D = rand(dims, dims)\n",
    "I = rand(dims, dims, dims, dims)\n",
    "\n",
    "# Build the Fock matrix using loops, while keeping track of time\n",
    "println(\"Time for loop G build:\")\n",
    "Gloop = @btime begin\n",
    "   Gloop = np.zeros((dims, dims))\n",
    "   @inbounds for ind in CartesianIndices(I)\n",
    "       p, q, r, s = Tuple(ind)\n",
    "       Gloop[p, q] += 2I[p, q, r, s] * D[r, s]\n",
    "       Gloop[p, q] -=  I[p, r, q, s] * D[r, s]\n",
    "   end\n",
    "   Gloop\n",
    "end\n",
    "\n",
    "# Build the Fock matrix using einsum, while keeping track of time\n",
    "println(\"Time for @tensor G build:\")\n",
    "G = @btime @tensor G[p,q] := 2I[p,q,r,s] * D[r,s] - I[p,r,q,s] * D[r,s]\n",
    "\n",
    "# Make sure the correct answer is obtained\n",
    "println(\"Loop and einsum builds of the Fock matrix match?    \", np.allclose(G, Gloop))\n",
    "println()\n",
    "# Print out relative times for explicit loop vs einsum Fock builds\n",
    "#println(\"G builds with einsum are $(g_loop_time/einsum_time) times faster than Julia loops!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `@tensor` macro can be considerably faster than plain Julia loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication chain/train\n",
    "\n",
    "Now let us turn our attention to a more canonical matrix multiplication example such as:\n",
    "$$D_{il} = A_{ij} B_{jk} C_{kl}$$\n",
    "\n",
    "Matrix multiplication is an extremely common operation in all branches of linear algebra. Thus, these functions have been optimized to be extremely efficient. `@tensor` uses it. The matrix product will explicitly compute the following operation:\n",
    "$$C_{ij} = A_{ij} * B_{ij}$$\n",
    "\n",
    "\n",
    "This is Julia's matrix multiplication method `*` for matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair product allclose? true\n"
     ]
    }
   ],
   "source": [
    "dims = 200\n",
    "A = rand(dims, dims)\n",
    "B = rand(dims, dims)\n",
    "C = rand(dims, dims)\n",
    "\n",
    "# First compute the pair product\n",
    "tmp_dot = A * B\n",
    "@tensor tmp_tensor[i,k] := A[i,j] * B[j,k]\n",
    "println(\"Pair product allclose? \", np.allclose(tmp_dot, tmp_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have proved exactly what `*` product does, let us consider the full chain and do a timing comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain multiplication allclose? true\n"
     ]
    }
   ],
   "source": [
    "D_dot = A * B * C\n",
    "@tensor D_tensor[i,l] := A[i,j] * B[j,k] * C[k,l]\n",
    "println(\"Chain multiplication allclose? \", np.allclose(D_dot, D_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* time:\n",
      "  467.984 μs (4 allocations: 625.16 KiB)\n",
      "\n",
      "@tensor time:\n",
      "  471.215 μs (34 allocations: 314.20 KiB)\n"
     ]
    }
   ],
   "source": [
    "println()\n",
    "println(\"* time:\")\n",
    "@btime A * B * C\n",
    "\n",
    "println()\n",
    "println(\"@tensor time:\")\n",
    "@btime @tensor D_tensor[i,l] := A[i,j] * B[j,k] * C[k,l];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both have similar timings, and both call [Basic Linear Algebra Subprograms (BLAS)](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms). The BLAS routines are highly optimized and threaded versions of the code.\n",
    " - The `@tensor` code will factorize the operation by default; Thus, the overall cost is not ${\\cal O}(N^4)$ (as there are four indices) rather it is the factored $(\\bf{A B}) \\bf{C}$ which runs ${\\cal O}(N^3)$.\n",
    " \n",
    "Therefore you do not need to factorize the expression yourself (sometimes you might need):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tensor factorized time:\n",
      "  474.136 μs (8 allocations: 625.25 KiB)\n"
     ]
    }
   ],
   "source": [
    "println(\"@tensor factorized time:\")\n",
    "@btime @tensor begin\n",
    "   tmp[i,k]  := A[i,j] * B[j,k]\n",
    "   tmp2[i,l] := tmp[i,k] * C[k,l]\n",
    "end\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On most machines the three have similar timings. The BLAS usage is usually recommended. Thankfully, in Julia its syntax is very clear. The Psi4Julia project tends to lean toward usage of tensor packages but if Julia's built-in matrix multiplication is significantly cleaner/faster we would use it. The real value of tensor packages will become tangible for more complicated expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complicated tensor manipulations\n",
    "Let us consider a popular index transformation example:\n",
    "$$M_{pqrs} = C_{pi} C_{qj} I_{ijkl} C_{rk} C_{sl}$$\n",
    "\n",
    "Here, a naive loop implementation would scale like $\\mathcal{O}(N^8)$ which translates to an extremely costly computation for all but the smallest $N$. A smarter implementation (factorizing the whole expression) would scale\n",
    "like $\\mathcal{O}(N^5)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**WARNING: First execution is slow because of compilation time. Successive are more honest to the running time.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting @tensor full transformation...complete in 0.008222635 s\n",
      "\n",
      "Starting @tensor factorized N^5 transformation with einsum ... complete in 0.000705554 s \n",
      "  @tensor factorized is 11.65415404065458 faster than full @tensor algorithm!\n",
      "  Allclose? true\n",
      "\n",
      "Starting Julia's factorized transformation with * ... complete in 0.001960656 s \n",
      "  * factorized is 4.193818293469126 faster than full @tensor algorithm!\n",
      "  Allclose? true\n"
     ]
    }
   ],
   "source": [
    "# Grab orbitals\n",
    "dims = 15\n",
    "@assert dims <= 15 || \"Size must be smaller than 15.\"\n",
    "    \n",
    "C = rand(dims, dims)\n",
    "I = rand(dims, dims, dims, dims)\n",
    "\n",
    "# @tensor full transformation.\n",
    "print(\"\\nStarting @tensor full transformation...\")\n",
    "n8_time = @elapsed @tensor MO_n8[I,J,K,L] := C[p,I] * C[q,J] * I[p,q,r,s] * C[r,K] * C[s,L]\n",
    "print(\"complete in $n8_time s\\n\")\n",
    "\n",
    "# @tensor factorized N^5 transformation.\n",
    "print(\"\\nStarting @tensor factorized N^5 transformation with einsum ... \")\n",
    "n5_time = @elapsed @tensor begin\n",
    "   MO_n5[A,q,r,s] := C[p,A] * I[p,q,r,s]\n",
    "   MO_n5[A,B,r,s] := C[q,B] * MO_n5[A,q,r,s]\n",
    "   MO_n5[A,B,C,s] := C[r,C] * MO_n5[A,B,r,s]\n",
    "   MO_n5[A,B,C,D] := C[s,D] * MO_n5[A,B,C,s]\n",
    "end\n",
    "print(\"complete in $n5_time s \\n\")\n",
    "println(\"  @tensor factorized is $(n8_time/n5_time) faster than full @tensor algorithm!\")\n",
    "println(\"  Allclose? \", np.allclose(MO_n8, MO_n5))\n",
    "\n",
    "# Julia's GEMM N^5 transformation.\n",
    "# Try to figure this one out!\n",
    "print(\"\\nStarting Julia's factorized transformation with * ... \")\n",
    "dgemm_time = @elapsed begin\n",
    "   MO = C' * reshape(I, dims, :)\n",
    "   MO = reshape(MO, :, dims) * C\n",
    "   MO = permutedims(reshape(MO, dims, dims, dims, dims), (2, 1, 4, 3))\n",
    "\n",
    "   MO = C' * reshape(MO, dims, :)\n",
    "   MO = reshape(MO, :, dims) * C\n",
    "   MO = permutedims(reshape(MO, dims, dims, dims, dims),(2, 1, 4, 3))\n",
    "end\n",
    "print(\"complete in $dgemm_time s \\n\")\n",
    "println(\"  * factorized is $(n8_time/dgemm_time) faster than full @tensor algorithm!\")\n",
    "println(\"  Allclose? \", np.allclose(MO_n8, MO))\n",
    "\n",
    "# There are still several possibilities to explore:\n",
    "# @inbounds, @simd, LinearAlgebra.LAPACK calls, Einsum.jl, Tullio.jl, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "None of the above algorithms is $\\mathcal{O}(N^8)$. `@tensor` factorizes the expression to achieve better performance. There is a small edge in doing the factorization manually. Factorized algorithms have similar timings, although it is clear that with `@tensor` is easier than with Julia's built-in `*`. To use the usual matrix multiplication with tensors we have to reshape and permute their dimensions, subtracting appeal to the simple `*` syntax."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "jl:light,ipynb"
  },
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
